"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = void 0;

function _assert() {
  const data = _interopRequireDefault(require("assert"));

  _assert = function () {
    return data;
  };

  return data;
}

function _path() {
  const data = _interopRequireDefault(require("path"));

  _path = function () {
    return data;
  };

  return data;
}

function _nullthrows() {
  const data = _interopRequireDefault(require("nullthrows"));

  _nullthrows = function () {
    return data;
  };

  return data;
}

function _utils() {
  const data = require("@parcel/utils");

  _utils = function () {
    return data;
  };

  return data;
}

function _logger() {
  const data = _interopRequireWildcard(require("@parcel/logger"));

  _logger = function () {
    return data;
  };

  return data;
}

function _sourceMap() {
  const data = require("@parcel/source-map");

  _sourceMap = function () {
    return data;
  };

  return data;
}

function _diagnostic() {
  const data = _interopRequireWildcard(require("@parcel/diagnostic"));

  _diagnostic = function () {
    return data;
  };

  return data;
}

function _ConfigLoader() {
  const data = _interopRequireDefault(require("./ConfigLoader"));

  _ConfigLoader = function () {
    return data;
  };

  return data;
}

function _Dependency() {
  const data = require("./Dependency");

  _Dependency = function () {
    return data;
  };

  return data;
}

function _ParcelConfig() {
  const data = _interopRequireDefault(require("./ParcelConfig"));

  _ParcelConfig = function () {
    return data;
  };

  return data;
}

function _PathRequest() {
  const data = require("./requests/PathRequest");

  _PathRequest = function () {
    return data;
  };

  return data;
}

function _Asset() {
  const data = require("./public/Asset");

  _Asset = function () {
    return data;
  };

  return data;
}

function _UncommittedAsset() {
  const data = _interopRequireDefault(require("./UncommittedAsset"));

  _UncommittedAsset = function () {
    return data;
  };

  return data;
}

function _assetUtils() {
  const data = require("./assetUtils");

  _assetUtils = function () {
    return data;
  };

  return data;
}

function _summarizeRequest() {
  const data = _interopRequireDefault(require("./summarizeRequest"));

  _summarizeRequest = function () {
    return data;
  };

  return data;
}

function _PluginOptions() {
  const data = _interopRequireDefault(require("./public/PluginOptions"));

  _PluginOptions = function () {
    return data;
  };

  return data;
}

function _constants() {
  const data = require("./constants");

  _constants = function () {
    return data;
  };

  return data;
}

function _utils2() {
  const data = require("./utils");

  _utils2 = function () {
    return data;
  };

  return data;
}

function _getRequireWildcardCache() { if (typeof WeakMap !== "function") return null; var cache = new WeakMap(); _getRequireWildcardCache = function () { return cache; }; return cache; }

function _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } if (obj === null || typeof obj !== "object" && typeof obj !== "function") { return { default: obj }; } var cache = _getRequireWildcardCache(); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj.default = obj; if (cache) { cache.set(obj, newObj); } return newObj; }

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

class Transformation {
  constructor({
    report,
    request,
    options,
    config,
    workerApi
  }) {
    _defineProperty(this, "request", void 0);

    _defineProperty(this, "configLoader", void 0);

    _defineProperty(this, "configRequests", void 0);

    _defineProperty(this, "options", void 0);

    _defineProperty(this, "pluginOptions", void 0);

    _defineProperty(this, "workerApi", void 0);

    _defineProperty(this, "parcelConfig", void 0);

    _defineProperty(this, "report", void 0);

    _defineProperty(this, "invalidations", void 0);

    this.configRequests = [];
    this.configLoader = new (_ConfigLoader().default)({
      options,
      config
    });
    this.parcelConfig = config;
    this.options = options;
    this.report = report;
    this.request = request;
    this.workerApi = workerApi;
    this.invalidations = new Map();
    this.pluginOptions = new (_PluginOptions().default)((0, _utils2().optionsProxy)(this.options, option => {
      let invalidation = {
        type: 'option',
        key: option
      };
      this.invalidations.set((0, _assetUtils().getInvalidationId)(invalidation), invalidation);
    }));
  }

  async loadConfig(configRequest) {
    let result = await this.configLoader.load(configRequest);
    this.configRequests.push({
      request: configRequest,
      result
    });
    return result;
  }

  async run() {
    await _sourceMap().init;
    this.report({
      type: 'buildProgress',
      phase: 'transforming',
      filePath: this.request.filePath
    });
    let asset = await this.loadAsset(); // Load existing sourcemaps

    if (_utils().SOURCEMAP_EXTENSIONS.has(asset.value.type)) {
      try {
        await asset.loadExistingSourcemap();
      } catch (err) {
        _logger().default.verbose([{
          origin: '@parcel/core',
          message: `Could not load existing source map for ${(0, _utils().escapeMarkdown)(_path().default.relative(this.options.projectRoot, asset.value.filePath))}`,
          filePath: asset.value.filePath
        }, {
          origin: '@parcel/core',
          message: (0, _utils().escapeMarkdown)(err.message),
          filePath: asset.value.filePath
        }]);
      }
    }

    let pipeline = await this.loadPipeline(this.request.filePath, asset.value.isSource, asset.value.pipeline);
    let results = await this.runPipelines(pipeline, asset);
    let assets = results.map(a => a.value);

    for (let {
      request,
      result
    } of this.configRequests) {
      if (request.plugin != null) {
        let resolveFrom = request.meta.parcelConfigPath;
        let keyPath = request.meta.parcelConfigKeyPath;
        (0, _assert().default)(typeof resolveFrom === 'string', 'request.meta.parcelConfigPath should be a string!');
        (0, _assert().default)(typeof keyPath === 'string', 'request.meta.parcelConfigKeyPath should be a string!');
        let {
          plugin
        } = await this.parcelConfig.loadPlugin({
          packageName: request.plugin,
          resolveFrom,
          keyPath
        });

        if (plugin && plugin.preSerializeConfig) {
          plugin.preSerializeConfig({
            config: result
          });
        }
      }
    }

    return {
      assets,
      configRequests: this.configRequests,
      invalidations: [...this.invalidations.values()]
    };
  }

  async loadAsset() {
    let {
      filePath,
      env,
      code,
      pipeline,
      isSource: isSourceOverride,
      sideEffects,
      query
    } = this.request;
    let {
      content,
      size,
      hash,
      isSource: summarizedIsSource
    } = await (0, _summarizeRequest().default)(this.options.inputFS, {
      filePath,
      code
    }); // Prefer `isSource` originating from the AssetRequest.

    let isSource = isSourceOverride !== null && isSourceOverride !== void 0 ? isSourceOverride : summarizedIsSource; // If the transformer request passed code rather than a filename,
    // use a hash as the base for the id to ensure it is unique.

    let idBase = code != null ? hash : (0, _utils().normalizeSeparators)(_path().default.relative(this.options.projectRoot, filePath));
    return new (_UncommittedAsset().default)({
      idBase,
      value: (0, _assetUtils().createAsset)({
        idBase,
        filePath,
        isSource,
        type: _path().default.extname(filePath).slice(1),
        hash,
        pipeline,
        env,
        query,
        stats: {
          time: 0,
          size
        },
        sideEffects
      }),
      options: this.options,
      content,
      invalidations: this.invalidations
    });
  }

  async runPipelines(pipeline, initialAsset) {
    let initialType = initialAsset.value.type;
    let initialAssetCacheKey = this.getCacheKey([initialAsset], pipeline.configs, await (0, _assetUtils().getInvalidationHash)(this.request.invalidations || [], this.options));
    let initialCacheEntry = await this.readFromCache(initialAssetCacheKey);
    let assets = initialCacheEntry || (await this.runPipeline(pipeline, initialAsset));

    if (!initialCacheEntry) {
      let resultCacheKey = this.getCacheKey([initialAsset], pipeline.configs, await (0, _assetUtils().getInvalidationHash)(assets.flatMap(asset => asset.getInvalidations()), this.options));
      await this.writeToCache(resultCacheKey, assets, pipeline.configs);
    }

    let finalAssets = [];

    for (let asset of assets) {
      let nextPipeline;

      if (asset.value.type !== initialType) {
        nextPipeline = await this.loadNextPipeline({
          filePath: initialAsset.value.filePath,
          isSource: asset.value.isSource,
          newType: asset.value.type,
          newPipeline: asset.value.pipeline,
          currentPipeline: pipeline
        });
      }

      if (nextPipeline) {
        let nextPipelineAssets = await this.runPipelines(nextPipeline, asset);
        finalAssets = finalAssets.concat(nextPipelineAssets);
      } else {
        finalAssets.push(asset);
      }
    }

    return finalAssets;
  }

  async runPipeline(pipeline, initialAsset) {
    if (pipeline.transformers.length === 0) {
      return [initialAsset];
    }

    let initialType = initialAsset.value.type;
    let inputAssets = [initialAsset];
    let resultingAssets = [];
    let finalAssets = [];

    for (let transformer of pipeline.transformers) {
      resultingAssets = [];

      for (let asset of inputAssets) {
        if (asset.value.type !== initialType && (await this.loadNextPipeline({
          filePath: initialAsset.value.filePath,
          isSource: asset.value.isSource,
          newType: asset.value.type,
          newPipeline: asset.value.pipeline,
          currentPipeline: pipeline
        }))) {
          finalAssets.push(asset);
          continue;
        }

        try {
          let transformerResults = await runTransformer(pipeline, asset, transformer.plugin, transformer.name, transformer.config);

          for (let result of transformerResults) {
            resultingAssets.push(asset.createChildAsset(result, transformer.name, this.parcelConfig.filePath, transformer.configKeyPath));
          }
        } catch (e) {
          throw new (_diagnostic().default)({
            diagnostic: (0, _diagnostic().errorToDiagnostic)(e, transformer.name)
          });
        }
      }

      inputAssets = resultingAssets;
    } // Make assets with ASTs generate unless they are js assets and target uses
    // scope hoisting or we do CSS modules tree shaking. This parallelizes generation
    // and distributes work more evenly across workers than if one worker needed to
    // generate all assets in a large bundle during packaging.


    let generate = pipeline.generate;

    if (generate != null) {
      await Promise.all(resultingAssets.filter(asset => asset.ast != null && !(asset.value.env.shouldScopeHoist && asset.value.type === 'js' || this.options.mode === 'production' && asset.value.type === 'css' && asset.value.symbols)).map(async asset => {
        if (asset.isASTDirty) {
          var _output$map;

          let output = await generate(asset);
          asset.content = output.content;
          asset.mapBuffer = (_output$map = output.map) === null || _output$map === void 0 ? void 0 : _output$map.toBuffer();
        }

        asset.clearAST();
      }));
    }

    return finalAssets.concat(resultingAssets);
  }

  async readFromCache(cacheKey) {
    if (this.options.shouldDisableCache || this.request.code != null) {
      return null;
    }

    let cachedAssets = await this.options.cache.get(cacheKey);

    if (!cachedAssets) {
      return null;
    }

    return Promise.all(cachedAssets.map(async value => {
      let content = value.contentKey != null ? this.options.cache.getStream(value.contentKey) : null;
      let mapBuffer = value.astKey != null ? await this.options.cache.getBlob(value.astKey) : null;
      let ast = value.astKey != null ? await this.options.cache.getBlob(value.astKey) : null;
      return new (_UncommittedAsset().default)({
        value,
        options: this.options,
        content,
        mapBuffer,
        ast
      });
    }));
  }

  async writeToCache(cacheKey, assets, configs) {
    await Promise.all(assets.map(asset => asset.commit((0, _utils().md5FromOrderedObject)({
      configs: getImpactfulConfigInfo(configs)
    }))));
    this.options.cache.set(cacheKey, assets.map(a => a.value));
  }

  getCacheKey(assets, configs, invalidationHash) {
    let assetsKeyInfo = assets.map(a => ({
      filePath: a.value.filePath,
      pipeline: a.value.pipeline,
      hash: a.value.hash,
      uniqueKey: a.value.uniqueKey,
      query: a.value.query ? (0, _utils().objectSortedEntries)(a.value.query) : ''
    }));
    return (0, _utils().md5FromOrderedObject)({
      parcelVersion: _constants().PARCEL_VERSION,
      assets: assetsKeyInfo,
      configs: getImpactfulConfigInfo(configs),
      env: this.request.env,
      invalidationHash
    });
  }

  async loadPipeline(filePath, isSource, pipeline) {
    let configRequest = {
      filePath,
      env: this.request.env,
      isSource,
      pipeline: pipeline,
      isURL: this.request.isURL,
      meta: {
        actionType: 'transformation'
      }
    };
    let configs = new Map();
    let config = await this.loadConfig(configRequest);
    configs.set('parcel', config);
    let transformers = await this.parcelConfig.getTransformers(filePath, pipeline, this.request.isURL);

    for (let {
      name,
      resolveFrom,
      keyPath
    } of transformers) {
      let thirdPartyConfig = await this.loadTransformerConfig({
        filePath,
        plugin: name,
        parcelConfigPath: resolveFrom,
        parcelConfigKeyPath: keyPath,
        isSource
      });
      configs.set(name, thirdPartyConfig);
    }

    return {
      id: transformers.map(t => t.name).join(':'),
      transformers: transformers.map(transformer => {
        var _configs$get;

        return {
          name: transformer.name,
          config: (_configs$get = configs.get(transformer.name)) === null || _configs$get === void 0 ? void 0 : _configs$get.result,
          configKeyPath: transformer.keyPath,
          plugin: transformer.plugin
        };
      }),
      configs,
      options: this.options,
      resolverRunner: new (_PathRequest().ResolverRunner)({
        config: this.parcelConfig,
        options: this.options
      }),
      pluginOptions: this.pluginOptions,
      workerApi: this.workerApi
    };
  }

  async loadNextPipeline({
    filePath,
    isSource,
    newType,
    newPipeline,
    currentPipeline
  }) {
    let nextFilePath = filePath.slice(0, -_path().default.extname(filePath).length) + '.' + newType;
    let nextPipeline = await this.loadPipeline(nextFilePath, isSource, newPipeline);

    if (nextPipeline.id === currentPipeline.id) {
      return null;
    }

    return nextPipeline;
  }

  loadTransformerConfig({
    filePath,
    plugin,
    parcelConfigPath,
    parcelConfigKeyPath,
    isSource
  }) {
    let configRequest = {
      filePath,
      env: this.request.env,
      plugin,
      isSource,
      meta: {
        parcelConfigPath,
        parcelConfigKeyPath
      }
    };
    return this.loadConfig(configRequest);
  }

}

exports.default = Transformation;

async function runTransformer(pipeline, asset, transformer, transformerName, preloadedConfig) {
  const logger = new (_logger().PluginLogger)({
    origin: transformerName
  });

  const resolve = async (from, to) => {
    return (0, _nullthrows().default)(await pipeline.resolverRunner.resolve((0, _Dependency().createDependency)({
      env: asset.value.env,
      moduleSpecifier: to,
      sourcePath: from
    }))).filePath;
  }; // If an ast exists on the asset, but we cannot reuse it,
  // use the previous transform to generate code that we can re-parse.


  if (asset.ast && asset.isASTDirty && (!transformer.canReuseAST || !transformer.canReuseAST({
    ast: asset.ast,
    options: pipeline.pluginOptions,
    logger
  })) && pipeline.generate) {
    var _output$map2;

    let output = await pipeline.generate(asset);
    asset.content = output.content;
    asset.mapBuffer = (_output$map2 = output.map) === null || _output$map2 === void 0 ? void 0 : _output$map2.toBuffer();
  } // Load config for the transformer.


  let config = preloadedConfig; // Parse if there is no AST available from a previous transform.

  if (!asset.ast && transformer.parse) {
    let ast = await transformer.parse({
      asset: new (_Asset().MutableAsset)(asset),
      config,
      options: pipeline.pluginOptions,
      resolve,
      logger
    });

    if (ast) {
      asset.setAST(ast);
      asset.isASTDirty = false;
    }
  } // Transform.


  let results = await normalizeAssets( // $FlowFixMe
  await transformer.transform({
    asset: new (_Asset().MutableAsset)(asset),
    ast: asset.ast,
    config,
    options: pipeline.pluginOptions,
    resolve,
    logger
  })); // Create generate functions that can be called later

  pipeline.generate = input => {
    if (transformer.generate && input.ast) {
      let generated = transformer.generate({
        asset: new (_Asset().Asset)(input),
        ast: input.ast,
        options: pipeline.pluginOptions,
        logger
      });
      input.clearAST();
      return Promise.resolve(generated);
    }

    throw new Error('Asset has an AST but no generate method is available on the transform');
  };

  return results;
}

function normalizeAssets(results) {
  return Promise.all(results.map(async result => {
    if (!(result instanceof _Asset().MutableAsset)) {
      return result;
    }

    let internalAsset = (0, _Asset().mutableAssetToUncommittedAsset)(result); // $FlowFixMe - ignore id already on env

    return {
      ast: internalAsset.ast,
      content: await internalAsset.content,
      query: internalAsset.value.query,
      // $FlowFixMe
      dependencies: [...internalAsset.value.dependencies.values()],
      env: internalAsset.value.env,
      filePath: result.filePath,
      isInline: result.isInline,
      isIsolated: result.isIsolated,
      map: await internalAsset.getMap(),
      meta: result.meta,
      pipeline: internalAsset.value.pipeline,
      // $FlowFixMe
      symbols: internalAsset.value.symbols,
      type: result.type,
      uniqueKey: internalAsset.value.uniqueKey
    };
  }));
}

function getImpactfulConfigInfo(configs) {
  let impactfulConfigInfo = {};

  for (let [configType, {
    devDeps,
    resultHash
  }] of configs) {
    let devDepsObject = {};

    for (let [moduleName, version] of devDeps) {
      devDepsObject[moduleName] = version;
    }

    impactfulConfigInfo[configType] = {
      devDeps: devDepsObject,
      resultHash
    };
  }

  return impactfulConfigInfo;
}